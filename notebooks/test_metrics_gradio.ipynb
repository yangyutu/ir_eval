{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import bm25s\n",
    "import os, gzip, json\n",
    "from sentence_transformers import util\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_filepath = \"./data/simplewiki-2020-11-01.jsonl.gz\"\n",
    "embedding_save_path = \"./dta/simple_wikipedia.pk\"\n",
    "\n",
    "if not os.path.exists(wikipedia_filepath):\n",
    "    util.http_get(\"http://sbert.net/datasets/simplewiki-2020-11-01.jsonl.gz\", wikipedia_filepath)\n",
    "\n",
    "passages_first_sentence = []\n",
    "with gzip.open(wikipedia_filepath, \"rt\", encoding=\"utf8\") as fIn:\n",
    "    for line in fIn:\n",
    "        data = json.loads(line.strip())\n",
    "        passages_first_sentence.append(data[\"paragraphs\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(embedding_save_path):\n",
    "    corpus_embeddings = torch.load(embedding_save_path)\n",
    "else:\n",
    "# We encode all passages into our vector space. This takes about 5 minutes (depends on your GPU speed)\n",
    "    corpus_embeddings = bi_encoder.encode(passages, convert_to_tensor=True, show_progress_bar=True)\n",
    "    torch.save(corpus_embeddings, embedding_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset file at: .gradio/flagged/dataset1.csv\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name, intensity):\n",
    "    return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"slider\"],\n",
    "    outputs=[\"text\"],\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trec covid dataset\n",
    "https://paperswithcode.com/dataset/trec-covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_dataset(\"BeIR/trec-covid\", 'corpus')['corpus']\n",
    "queries = load_dataset(\"BeIR/trec-covid\", 'queries')['queries']\n",
    "qrels = load_dataset(\"BeIR/trec-covid-qrels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'title', 'text'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(example):\n",
    "    example['full_text'] = '[Title] ' + example['title'] + ' [TEXT] ' + example['text']\n",
    "    return example\n",
    "corpus = corpus.map(combine_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5355/5355 [01:25<00:00, 62.98it/s] \n"
     ]
    }
   ],
   "source": [
    "corpus_embeddings = model.encode(corpus['full_text'], convert_to_tensor=True, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:00<00:00, 100.12it/s]\n"
     ]
    }
   ],
   "source": [
    "query_embeddings = model.encode(queries['text'], convert_to_tensor=True, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 384])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = util.semantic_search(query_embeddings, corpus_embeddings, top_k=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retrieval_results = collections.defaultdict(dict)\n",
    "doc_id_map = corpus['_id']\n",
    "query_id_map = queries['_id']\n",
    "for qid, doc_score_list in enumerate(hits):\n",
    "    qid_key = query_id_map[qid]\n",
    "    result_dict = {}\n",
    "    doc_ids = [doc_score['corpus_id'] for doc_score in doc_score_list]\n",
    "    scores = [doc_score['score'] for doc_score in doc_score_list]\n",
    "    \n",
    "    doc_id_keys = list(map(lambda x: doc_id_map[x], doc_ids))\n",
    "    result_dict = dict(zip(doc_id_keys, scores))\n",
    "    retrieval_results[qid_key] = result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_for_eval = collections.defaultdict(dict)\n",
    "for example in qrels['test']:\n",
    "    qrels_for_eval[str(example['query-id'])][str(example['corpus-id'])] = example['score']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Recall@1': 0.00191,\n",
       " 'Recall@3': 0.00488,\n",
       " 'Recall@5': 0.00775,\n",
       " 'Recall@10': 0.01431,\n",
       " 'Recall@20': 0.02549,\n",
       " 'Recall@30': 0.03588,\n",
       " 'Recall@100': 0.09415,\n",
       " 'Recall@500': 0.2493,\n",
       " 'Recall@2000': 0.44927}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(qrels=qrels_for_eval, results=retrieval_results, k_values=[1, 3, 5, 10, 20, 30, 100, 500, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision@1': 0.74,\n",
       " 'Precision@3': 0.64667,\n",
       " 'Precision@5': 0.612,\n",
       " 'Precision@10': 0.564,\n",
       " 'Precision@20': 0.503,\n",
       " 'Precision@30': 0.484,\n",
       " 'Precision@100': 0.3974,\n",
       " 'Precision@500': 0.22796,\n",
       " 'Precision@2000': 0.10729}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(qrels=qrels_for_eval, results=retrieval_results, k_values=[1, 3, 5, 10, 20, 30, 100, 500, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDCG@1': 0.67, 'NDCG@3': 0.60222, 'NDCG@5': 0.57071, 'NDCG@10': 0.53565}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg(qrels=qrels_for_eval, results=retrieval_results, k_values=[1, 3, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_lastest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
