{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from ir_eval.metrics import recall, precision, hole, ndcg\n",
    "from sentence_transformers import SentenceTransformer, util, CrossEncoder\n",
    "from ir_eval.utils_prompt import load_prompt_text, eval_prompt, preprocess_prompt\n",
    "import collections\n",
    "import os\n",
    "import json\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trec covid dataset\n",
    "https://paperswithcode.com/dataset/trec-covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_dataset(\"BeIR/trec-covid\", 'corpus')['corpus']\n",
    "queries = load_dataset(\"BeIR/trec-covid\", 'queries')['queries']\n",
    "qrels = load_dataset(\"BeIR/trec-covid-qrels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(example):\n",
    "    example['full_text'] = '[Title] ' + example['title'] + ' [TEXT] ' + example['text']\n",
    "    return example\n",
    "corpus = corpus.map(combine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_for_eval = collections.defaultdict(dict)\n",
    "for example in qrels['test']:\n",
    "    qrels_for_eval[str(example['query-id'])][str(example['corpus-id'])] = example['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c318a64e42714d9597b7fa6faac18e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365888079eb54f618c83f9fcbbe31f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba400f406584d92bb1a6b92af1ad17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2813377bf664db887c1903bddd0c475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d421c40d1047f891a9ecfa91e79f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e1446f162843219f006bb7c2aac8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8503da758d44370a15fa2799fc8ebb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56696edb3e3473f82a16f76fbecf491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204acb37f6d24cdc9630251f93f2ef59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17bffd317174e109c216ef95e91bfcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d3b82b767b4e1aa2ad8415b92661a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "model = SentenceTransformer(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieval_results(query_embeddings, corpus_embeddings, top_k=10):\n",
    "    hits = util.semantic_search(query_embeddings, corpus_embeddings, top_k=top_k)\n",
    "    retrieval_results = collections.defaultdict(dict)\n",
    "    doc_id_map = corpus['_id']\n",
    "    query_id_map = queries['_id']\n",
    "    for qid, doc_score_list in enumerate(hits):\n",
    "        qid_key = query_id_map[qid]\n",
    "        result_dict = {}\n",
    "        doc_ids = [doc_score['corpus_id'] for doc_score in doc_score_list]\n",
    "        scores = [doc_score['score'] for doc_score in doc_score_list]\n",
    "        \n",
    "        doc_id_keys = list(map(lambda x: doc_id_map[x], doc_ids))\n",
    "        result_dict = dict(zip(doc_id_keys, scores))\n",
    "        retrieval_results[qid_key] = result_dict\n",
    "    return retrieval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(retrieval_results, qrels_for_eval):\n",
    "    \n",
    "    print(recall(qrels=qrels_for_eval, results=retrieval_results, k_values=[1, 3, 5, 10, 20, 30, 100, 500, 2000]))\n",
    "    print(precision(qrels=qrels_for_eval, results=retrieval_results, k_values=[1, 3, 5, 10, 20, 30, 100, 500, 2000]))\n",
    "    print(ndcg(qrels=qrels_for_eval, results=retrieval_results, k_values=[1, 3, 5, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db6245df9b444bd8ba2616c5bef8913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a5cbf376424b4ba89fbc41aa02feb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m query_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(queries[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m retrieval_results \u001b[38;5;241m=\u001b[39m get_retrieval_results(query_embeddings, corpus_embeddings, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretrieval_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqrels_for_eval\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(retrieval_results, qrels_for_eval)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21meval_model\u001b[39m(retrieval_results, qrels_for_eval):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mrecall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqrels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqrels_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretrieval_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(precision(qrels\u001b[38;5;241m=\u001b[39mqrels_for_eval, results\u001b[38;5;241m=\u001b[39mretrieval_results, k_values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m2000\u001b[39m]))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ndcg(qrels\u001b[38;5;241m=\u001b[39mqrels_for_eval, results\u001b[38;5;241m=\u001b[39mretrieval_results, k_values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m]))\n",
      "File \u001b[0;32m/mnt/d/Dropbox/llm_book/repos/ir_eval/src/ir_eval/metrics.py:23\u001b[0m, in \u001b[0;36mrecall\u001b[0;34m(qrels, results, k_values, relevance_score_thresh)\u001b[0m\n\u001b[1;32m     20\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m valid_qrel_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query_id, doc_scores \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# sort docs by predicted scores descendly\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     top_hits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(doc_scores\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m item:item[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m:k_max]\n\u001b[1;32m     26\u001b[0m     query_relevant_docs \u001b[38;5;241m=\u001b[39m [doc_id \u001b[38;5;28;01mfor\u001b[39;00m doc_id \u001b[38;5;129;01min\u001b[39;00m qrels[query_id] \u001b[38;5;28;01mif\u001b[39;00m qrels[query_id][doc_id] \u001b[38;5;241m>\u001b[39m relevance_score_thresh]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "corpus_embeddings = model.encode(corpus['full_text'], convert_to_tensor=True, show_progress_bar=True)\n",
    "query_embeddings = model.encode(queries['text'], convert_to_tensor=True, show_progress_bar=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Recall@1': 0.00179, 'Recall@3': 0.00488, 'Recall@5': 0.0079, 'Recall@10': 0.01548, 'Recall@20': 0.01548, 'Recall@30': 0.01548, 'Recall@100': 0.01548, 'Recall@500': 0.01548, 'Recall@2000': 0.01548}\n",
      "{'Precision@1': 0.6, 'Precision@3': 0.6, 'Precision@5': 0.592, 'Precision@10': 0.588, 'Precision@20': 0.294, 'Precision@30': 0.196, 'Precision@100': 0.0588, 'Precision@500': 0.01176, 'Precision@2000': 0.00294}\n",
      "{'NDCG@1': 0.54, 'NDCG@3': 0.54842, 'NDCG@5': 0.54485, 'NDCG@10': 0.53753}\n"
     ]
    }
   ],
   "source": [
    "retrieval_results = get_retrieval_results(query_embeddings, corpus_embeddings, top_k=10)\n",
    "eval_model(retrieval_results, qrels_for_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance record\n",
    "\n",
    "### sentence-transformers/all-mpnet-base-v2\n",
    "{'Recall@1': 0.00179, 'Recall@3': 0.00488, 'Recall@5': 0.0079, 'Recall@10': 0.01548, 'Recall@20': 0.01548, 'Recall@30': 0.01548, 'Recall@100': 0.01548, 'Recall@500': 0.01548, 'Recall@2000': 0.01548}\n",
    "{'Precision@1': 0.6, 'Precision@3': 0.6, 'Precision@5': 0.592, 'Precision@10': 0.588, 'Precision@20': 0.294, 'Precision@30': 0.196, 'Precision@100': 0.0588, 'Precision@500': 0.01176, 'Precision@2000': 0.00294}\n",
    "{'NDCG@1': 0.54, 'NDCG@3': 0.54842, 'NDCG@5': 0.54485, 'NDCG@10': 0.53753}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_lastest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
