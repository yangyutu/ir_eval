{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4syOJk5fKlP"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/milvus-io/bootcamp/blob/master/bootcamp/tutorials/quickstart/hybrid_search_with_milvus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>   <a href=\"https://github.com/milvus-io/bootcamp/blob/master/bootcamp/tutorials/quickstart/hybrid_search_with_milvus.ipynb\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/View%20on%20GitHub-555555?style=flat&logo=github&logoColor=white\" alt=\"GitHub Repository\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY1a3A_afKlP"
      },
      "source": [
        "# Hybrid Search with Dense and Sparse Vectors in Milvus\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/milvus-io/bootcamp/master/bootcamp/tutorials/quickstart/apps/hybrid_demo_with_milvus/pics/demo.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_N56McRfKlQ"
      },
      "source": [
        "In this tutorial, we will demonstrate how to conduct hybrid search with [Milvus](https://milvus.io/docs/multi-vector-search.md) and [BGE-M3 model](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/BGE_M3). BGE-M3 model can convert text into dense and sparse vectors. Milvus supports storing both types of vectors in one collection, allowing for hybrid search that enhances the result relevance.\n",
        "\n",
        "Milvus supports Dense, Sparse, and Hybrid retrieval methods:\n",
        "\n",
        "- Dense Retrieval: Utilizes semantic context to understand the meaning behind queries.\n",
        "- Sparse Retrieval: Emphasizes keyword matching to find results based on specific terms, equivalent to full-text search.\n",
        "- Hybrid Retrieval: Combines both Dense and Sparse approaches, capturing the full context and specific keywords for comprehensive search results.\n",
        "\n",
        "By integrating these methods, the Milvus Hybrid Search balances semantic and lexical similarities, improving the overall relevance of search outcomes. This notebook will walk through the process of setting up and using these retrieval strategies, highlighting their effectiveness in various search scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZcEZ0zZfKlQ"
      },
      "source": [
        "### Dependencies and Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3lwLUaN6fKlQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymilvus in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (2.5.4)\n",
            "Requirement already satisfied: setuptools>69 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from pymilvus) (75.8.0)\n",
            "Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from pymilvus) (1.67.1)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from pymilvus) (5.29.3)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from pymilvus) (1.0.1)\n",
            "Requirement already satisfied: ujson>=2.0.0 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from pymilvus) (5.10.0)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from pymilvus) (2.2.3)\n",
            "Requirement already satisfied: milvus-lite>=2.4.0 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from pymilvus) (2.4.11)\n",
            "Requirement already satisfied: milvus-model>=0.1.0 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from pymilvus[model]) (0.2.12)\n",
            "Requirement already satisfied: tqdm in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from milvus-lite>=2.4.0->pymilvus) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.36.0 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from milvus-model>=0.1.0->pymilvus[model]) (4.48.3)\n",
            "Requirement already satisfied: onnxruntime in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from milvus-model>=0.1.0->pymilvus[model]) (1.20.1)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from milvus-model>=0.1.0->pymilvus[model]) (1.15.1)\n",
            "Requirement already satisfied: numpy in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from milvus-model>=0.1.0->pymilvus[model]) (2.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n",
            "Requirement already satisfied: filelock in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (0.29.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2024.11.6)\n",
            "Requirement already satisfied: requests in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (0.5.2)\n",
            "Requirement already satisfied: coloredlogs in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from onnxruntime->milvus-model>=0.1.0->pymilvus[model]) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from onnxruntime->milvus-model>=0.1.0->pymilvus[model]) (25.2.10)\n",
            "Requirement already satisfied: sympy in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from onnxruntime->milvus-model>=0.1.0->pymilvus[model]) (1.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (4.12.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from coloredlogs->onnxruntime->milvus-model>=0.1.0->pymilvus[model]) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from requests->transformers>=4.36.0->milvus-model>=0.1.0->pymilvus[model]) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/yangyutu/miniconda3/envs/huggingface_lastest/lib/python3.11/site-packages (from sympy->onnxruntime->milvus-model>=0.1.0->pymilvus[model]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pymilvus \"pymilvus[model]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrt5B3HWfKlR"
      },
      "source": [
        "### Download Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q9RSEkQfKlR"
      },
      "source": [
        "To demonstrate search, we need a corpus of documents. Let's use the Quora Duplicate Questions dataset and place it in the local directory.\n",
        "\n",
        "Source of the dataset: [First Quora Dataset Release: Question Pairs](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5gIOf6NBfKlR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-02-22 22:27:17--  http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\n",
            "Resolving qim.fs.quoracdn.net (qim.fs.quoracdn.net)... 162.159.152.17, 162.159.153.247\n",
            "Connecting to qim.fs.quoracdn.net (qim.fs.quoracdn.net)|162.159.152.17|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://qim.fs.quoracdn.net/quora_duplicate_questions.tsv [following]\n",
            "--2025-02-22 22:27:17--  https://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\n",
            "Connecting to qim.fs.quoracdn.net (qim.fs.quoracdn.net)|162.159.152.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58176133 (55M) [text/tab-separated-values]\n",
            "Saving to: ‘quora_duplicate_questions.tsv’\n",
            "\n",
            "quora_duplicate_que 100%[===================>]  55.48M  19.0MB/s    in 2.9s    \n",
            "\n",
            "2025-02-22 22:27:20 (19.0 MB/s) - ‘quora_duplicate_questions.tsv’ saved [58176133/58176133]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to download the dataset\n",
        "!wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "colKh15xfKlR"
      },
      "source": [
        "### Load and Prepare Data\n",
        "\n",
        "We will load the dataset and prepare a small corpus for search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o8C3naRTfKlR",
        "outputId": "9f379fef-b099-4729-e947-aae706749e0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the difference between sincerity and fairness?\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"quora_duplicate_questions.tsv\"\n",
        "df = pd.read_csv(file_path, sep=\"\\t\")\n",
        "questions = set()\n",
        "for _, row in df.iterrows():\n",
        "    obj = row.to_dict()\n",
        "    questions.add(obj[\"question1\"][:512])\n",
        "    questions.add(obj[\"question2\"][:512])\n",
        "    if len(questions) > 500:  # Skip this if you want to use the full dataset\n",
        "        break\n",
        "\n",
        "docs = list(questions)\n",
        "\n",
        "# example question\n",
        "print(docs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_cdsJ3nfKlS"
      },
      "source": [
        "### Use BGE-M3 Model for Embeddings\n",
        "\n",
        "The BGE-M3 model can embed texts as dense and sparse vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iOxSM_bvfKlS",
        "outputId": "7930563b-45e6-4d1d-d70f-808b56e332d5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80add2069c0c4658ac263245081c0841",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "pre tokenize: 100%|██████████| 32/32 [00:00<00:00, 514.35it/s]\n",
            "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "Inference Embeddings: 100%|██████████| 32/32 [00:12<00:00,  2.52it/s]\n"
          ]
        }
      ],
      "source": [
        "from milvus_model.hybrid import BGEM3EmbeddingFunction\n",
        "\n",
        "ef = BGEM3EmbeddingFunction(use_fp16=False, device=\"cpu\")\n",
        "dense_dim = ef.dim[\"dense\"]\n",
        "\n",
        "# Generate embeddings using BGE-M3 model\n",
        "docs_embeddings = ef(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHX9WcpIfKlS"
      },
      "source": [
        "### Setup Milvus Collection and Index\n",
        "\n",
        "We will set up the Milvus collection and create indices for the vector fields.\n",
        "\n",
        "> - Setting the uri as a local file, e.g. \"./milvus.db\", is the most convenient method, as it automatically utilizes [Milvus Lite](https://milvus.io/docs/milvus_lite.md) to store all data in this file.\n",
        "> - If you have large scale of data, say more than a million vectors, you can set up a more performant Milvus server on [Docker or Kubernetes](https://milvus.io/docs/quickstart.md). In this setup, please use the server uri, e.g.http://localhost:19530, as your uri.\n",
        "> - If you want to use [Zilliz Cloud](https://zilliz.com/cloud), the fully managed cloud service for Milvus, adjust the uri and token, which correspond to the [Public Endpoint and API key](https://docs.zilliz.com/docs/on-zilliz-cloud-console#cluster-details) in Zilliz Cloud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2DJ6AO_4fKlS"
      },
      "outputs": [],
      "source": [
        "from pymilvus import (\n",
        "    connections,\n",
        "    utility,\n",
        "    FieldSchema,\n",
        "    CollectionSchema,\n",
        "    DataType,\n",
        "    Collection,\n",
        ")\n",
        "\n",
        "# Connect to Milvus given URI\n",
        "connections.connect(uri=\"./milvus.db\")\n",
        "\n",
        "# Specify the data schema for the new Collection\n",
        "fields = [\n",
        "    # Use auto generated id as primary key\n",
        "    FieldSchema(\n",
        "        name=\"pk\", dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100\n",
        "    ),\n",
        "    # Store the original text to retrieve based on semantically distance\n",
        "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=512),\n",
        "    # Milvus now supports both sparse and dense vectors,\n",
        "    # we can store each in a separate field to conduct hybrid search on both vectors\n",
        "    FieldSchema(name=\"sparse_vector\", dtype=DataType.SPARSE_FLOAT_VECTOR),\n",
        "    FieldSchema(name=\"dense_vector\", dtype=DataType.FLOAT_VECTOR, dim=dense_dim),\n",
        "]\n",
        "schema = CollectionSchema(fields)\n",
        "\n",
        "# Create collection (drop the old one if exists)\n",
        "col_name = \"hybrid_demo\"\n",
        "if utility.has_collection(col_name):\n",
        "    Collection(col_name).drop()\n",
        "col = Collection(col_name, schema, consistency_level=\"Strong\")\n",
        "\n",
        "# To make vector search efficient, we need to create indices for the vector fields\n",
        "sparse_index = {\"index_type\": \"SPARSE_INVERTED_INDEX\", \"metric_type\": \"IP\"}\n",
        "col.create_index(\"sparse_vector\", sparse_index)\n",
        "dense_index = {\"index_type\": \"AUTOINDEX\", \"metric_type\": \"IP\"}\n",
        "col.create_index(\"dense_vector\", dense_index)\n",
        "col.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0C5bwsIfKlS"
      },
      "source": [
        "### Insert Data into Milvus Collection\n",
        "\n",
        "Insert documents and their embeddings into the collection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EFFi-_3PfKlT",
        "outputId": "16c7f2ee-e190-410d-a340-b7a399b8168d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of entities inserted: 502\n"
          ]
        }
      ],
      "source": [
        "# For efficiency, we insert 50 records in each small batch\n",
        "for i in range(0, len(docs), 50):\n",
        "    batched_entities = [\n",
        "        docs[i : i + 50],\n",
        "        docs_embeddings[\"sparse\"][i : i + 50],\n",
        "        docs_embeddings[\"dense\"][i : i + 50],\n",
        "    ]\n",
        "    col.insert(batched_entities)\n",
        "print(\"Number of entities inserted:\", col.num_entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WlQMS_sfKlT"
      },
      "source": [
        "### Enter Your Search Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o4aPI4R9fKlT",
        "outputId": "65290904-5027-4df7-c159-58eedff0a2a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what is the capital of China\n"
          ]
        }
      ],
      "source": [
        "# Enter your search query\n",
        "query = input(\"Enter your search query: \")\n",
        "print(query)\n",
        "\n",
        "# Generate embeddings for the query\n",
        "query_embeddings = ef([query])\n",
        "# print(query_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar5DXkyDfKlT"
      },
      "source": [
        "### Run the Search\n",
        "\n",
        "We will first prepare some helpful functions to run the search:\n",
        "\n",
        "- `dense_search`: only search across dense vector field\n",
        "- `sparse_search`: only search across sparse vector field\n",
        "- `hybrid_search`: search across both dense and vector fields with a weighted reranker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cfjGyivifKlT"
      },
      "outputs": [],
      "source": [
        "from pymilvus import (\n",
        "    AnnSearchRequest,\n",
        "    WeightedRanker,\n",
        ")\n",
        "\n",
        "\n",
        "def dense_search(col, query_dense_embedding, limit=10):\n",
        "    search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
        "    res = col.search(\n",
        "        [query_dense_embedding],\n",
        "        anns_field=\"dense_vector\",\n",
        "        limit=limit,\n",
        "        output_fields=[\"text\"],\n",
        "        param=search_params,\n",
        "    )[0]\n",
        "    return [hit.get(\"text\") for hit in res]\n",
        "\n",
        "\n",
        "def sparse_search(col, query_sparse_embedding, limit=10):\n",
        "    search_params = {\n",
        "        \"metric_type\": \"IP\",\n",
        "        \"params\": {},\n",
        "    }\n",
        "    res = col.search(\n",
        "        [query_sparse_embedding],\n",
        "        anns_field=\"sparse_vector\",\n",
        "        limit=limit,\n",
        "        output_fields=[\"text\"],\n",
        "        param=search_params,\n",
        "    )[0]\n",
        "    return [hit.get(\"text\") for hit in res]\n",
        "\n",
        "\n",
        "def hybrid_search(\n",
        "    col,\n",
        "    query_dense_embedding,\n",
        "    query_sparse_embedding,\n",
        "    sparse_weight=1.0,\n",
        "    dense_weight=1.0,\n",
        "    limit=10,\n",
        "):\n",
        "    dense_search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
        "    dense_req = AnnSearchRequest(\n",
        "        [query_dense_embedding], \"dense_vector\", dense_search_params, limit=limit\n",
        "    )\n",
        "    sparse_search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
        "    sparse_req = AnnSearchRequest(\n",
        "        [query_sparse_embedding], \"sparse_vector\", sparse_search_params, limit=limit\n",
        "    )\n",
        "    rerank = WeightedRanker(sparse_weight, dense_weight)\n",
        "    res = col.hybrid_search(\n",
        "        [sparse_req, dense_req], rerank=rerank, limit=limit, output_fields=[\"text\"]\n",
        "    )[0]\n",
        "    return [hit.get(\"text\") for hit in res]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVWizP2jfKlT"
      },
      "source": [
        "Let's run three different searches with defined functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rJ6KR52cfKlT"
      },
      "outputs": [],
      "source": [
        "dense_results = dense_search(col, query_embeddings[\"dense\"][0])\n",
        "sparse_results = sparse_search(col, query_embeddings[\"sparse\"][[0]])\n",
        "hybrid_results = hybrid_search(\n",
        "    col,\n",
        "    query_embeddings[\"dense\"][0],\n",
        "    query_embeddings[\"sparse\"][[0]],\n",
        "    sparse_weight=0.7,\n",
        "    dense_weight=1.0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbDsQRSjfKlT"
      },
      "source": [
        "### Display Search Results\n",
        "\n",
        "To display the results for Dense, Sparse, and Hybrid searches, we need some utilities to format the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VJ03VuJRfKlT"
      },
      "outputs": [],
      "source": [
        "def doc_text_formatting(ef, query, docs):\n",
        "    tokenizer = ef.model.tokenizer\n",
        "    query_tokens_ids = tokenizer.encode(query, return_offsets_mapping=True)\n",
        "    query_tokens = tokenizer.convert_ids_to_tokens(query_tokens_ids)\n",
        "    formatted_texts = []\n",
        "\n",
        "    for doc in docs:\n",
        "        ldx = 0\n",
        "        landmarks = []\n",
        "        encoding = tokenizer.encode_plus(doc, return_offsets_mapping=True)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])[1:-1]\n",
        "        offsets = encoding[\"offset_mapping\"][1:-1]\n",
        "        for token, (start, end) in zip(tokens, offsets):\n",
        "            if token in query_tokens:\n",
        "                if len(landmarks) != 0 and start == landmarks[-1]:\n",
        "                    landmarks[-1] = end\n",
        "                else:\n",
        "                    landmarks.append(start)\n",
        "                    landmarks.append(end)\n",
        "        close = False\n",
        "        formatted_text = \"\"\n",
        "        for i, c in enumerate(doc):\n",
        "            if ldx == len(landmarks):\n",
        "                pass\n",
        "            elif i == landmarks[ldx]:\n",
        "                if close:\n",
        "                    formatted_text += \"</span>\"\n",
        "                else:\n",
        "                    formatted_text += \"<span style='color:red'>\"\n",
        "                close = not close\n",
        "                ldx = ldx + 1\n",
        "            formatted_text += c\n",
        "        if close is True:\n",
        "            formatted_text += \"</span>\"\n",
        "        formatted_texts.append(formatted_text)\n",
        "    return formatted_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHAghO4ffKlT"
      },
      "source": [
        "Then we can display search results in text with highlights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7fb-CLi_fKlT",
        "outputId": "0f0bdc7e-3b85-4c81-d6b9-353b812f372e"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "**Dense Search Results:**"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "How can I become fluent in chinese?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "How can I become more fluent in Chinese?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "What do you think China food?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "How do you think of Chinese food?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Is USA the most powerful country of the world?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Why is the USA the most powerful country of the world?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Why does China support Masood Azhar?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Why does China block sanctions at the UN against the Jaish-e-Mohammad (JeM) chief, Masood Azhar?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "How many Champions are there in League of Legends?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "What is purpose of life?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "\n",
              "**Sparse Search Results:**"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "What do you think<span style='color:red'> China</span> food?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Why does<span style='color:red'> China</span> support Masood Azhar?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Why does<span style='color:red'> China</span> block sanctions at<span style='color:red'> the</span> UN against<span style='color:red'> the</span> Jaish-e-Mohammad (JeM) chief, Masood Azhar?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "What<span style='color:red'> is the</span> meaning<span style='color:red'> of the</span> future?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Who<span style='color:red'> is the</span> father<span style='color:red'> of</span> lord Krishna?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "What<span style='color:red'> is</span> purpose<span style='color:red'> of</span> life?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Who<span style='color:red'> is the</span> best LoL (League<span style='color:red'> of</span> Legends) champion?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "How<span style='color:red'> is the</span> new Harry Potter book 'Harry Potter and<span style='color:red'> the</span> Cursed Child'?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Why<span style='color:red'> is the</span> USA<span style='color:red'> the</span> most powerful country<span style='color:red'> of the</span> world?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "What<span style='color:red'> is the</span> greatest mystery<span style='color:red'> of</span> all time?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "\n",
              "**Hybrid Search Results:**"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "What do you think<span style='color:red'> China</span> food?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Why does<span style='color:red'> China</span> support Masood Azhar?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Why does<span style='color:red'> China</span> block sanctions at<span style='color:red'> the</span> UN against<span style='color:red'> the</span> Jaish-e-Mohammad (JeM) chief, Masood Azhar?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Why<span style='color:red'> is the</span> USA<span style='color:red'> the</span> most powerful country<span style='color:red'> of the</span> world?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "What<span style='color:red'> is</span> purpose<span style='color:red'> of</span> life?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "How can I become fluent in chinese?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "How can I become more fluent in Chinese?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "How do you think<span style='color:red'> of</span> Chinese food?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Is USA<span style='color:red'> the</span> most powerful country<span style='color:red'> of the</span> world?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "How many Champions are there in League<span style='color:red'> of</span> Legends?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Dense search results\n",
        "display(Markdown(\"**Dense Search Results:**\"))\n",
        "formatted_results = doc_text_formatting(ef, query, dense_results)\n",
        "for result in dense_results:\n",
        "    display(Markdown(result))\n",
        "\n",
        "# Sparse search results\n",
        "display(Markdown(\"\\n**Sparse Search Results:**\"))\n",
        "formatted_results = doc_text_formatting(ef, query, sparse_results)\n",
        "for result in formatted_results:\n",
        "    display(Markdown(result))\n",
        "\n",
        "# Hybrid search results\n",
        "display(Markdown(\"\\n**Hybrid Search Results:**\"))\n",
        "formatted_results = doc_text_formatting(ef, query, hybrid_results)\n",
        "for result in formatted_results:\n",
        "    display(Markdown(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "628ETd1ofKlU"
      },
      "source": [
        "### Quick Deploy\n",
        "\n",
        "To learn about how to start an online demo with this tutorial, please refer to [the example application](https://github.com/milvus-io/bootcamp/tree/master/bootcamp/tutorials/quickstart/apps/hybrid_demo_with_milvus)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "huggingface_lastest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
